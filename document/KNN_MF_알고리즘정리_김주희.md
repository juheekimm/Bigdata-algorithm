# KNN (K-Nearest neighbor) Algorithm

최근접 이웃 알고리즘 : 지도학습 중 분류 문제에 사용하는 알고리즘으로, 새로운 데이터가 등장했을 때 분류하는 기법

유사한 특성을 가진 데이터는 유사한 범주에 속하는 경향이 있다는 가정하에 사용한다

이때 k의 크기(몇 번째로 가까운 데이터까지 살펴볼 것인가)에 따라 분류 결과가 달라진다.

같은 데이터여도 k의 값에 따라 분류 결과가 달라지기 때문에, 적절한 k를 정해주는 것이 중요하다.

<br>

## 1. 정규화

x와 y의 단위가 다른 경우, 결과치가 잘못 나올 수 있다.

그래서 KNN 알고리즘을 사용할 때는 모든 특성들을 고르게 반영하기 위해 정규화(Normalization)과정을 거치기도 한다.

1. 최소값을 0, 최대값을 1로 고정하고 모든 값을 0과 1 사이의 값으로 변환

2. 평균과 표준편차를 활용해서 평균으로부터 얼마나 떨어져 있는지 z-점수로 변환

    > Z점수: 편차를 표준편차로 나눈 값. 분포가 정규분포라는 가정하에서 원 점수의 평균을 0으로 하고, 표준편차를 1로 하는 변환점수를 의미한다. 평균으로부터의 편차점수를 그 분포의 표준편차로 나누어 얻어지는 점수.

<br>

## 2. K의 개수 선택 : k를 몇으로 정할 것인가

모든 값을 실제로 테스트하면서 `분류 정확도(Accuracy)`를 계산하는 과정에서 단서를 찾을 수 있다

이때, 분류 모델을 생성할 때 일부 데이터는  `검증에 활용(검증 세트)`되도록 떼어놓고 `학습 데이터(학습 세트)`로만 모델을 생성해서 검증 데이터를 넣어 분류 정확도(Accuray) 확인할 수 있다.

    학습 세트(Training Set) :  알고리즘이 학습할 데이터
    검증 세트(Validation Set) : 모델의 예측/분류 정확도를 계산하기 위한 데이터

    학습 데이터 세트를 사용하여 모델을 학습시키고 나면 이후에는 검증 세트를 통해 모델의 예측/분류 정확도를 계산할 수 있다. 
    
    사실 모든 검증 세트에 대한 실제 레이블, 즉 정답을 알고 있지만 그렇지 않은 척 하는 셈이다. 그래서 새로운 데이터인 것처럼 분류/예측 모델에 입력해준다. 실제로 학습 시킬 때 이 데이터들을 배제했기 때문에 가능하다.
    
    예측/분류된 값을 받아서 실제로 갖고 있던 답과 비교하기만 하면 정확도(Accuracy)를 알 수 있다.

<br>

## 3. K의 개수 선택 시 발생 가능한 문제점

### k가 너무 작을 때 : Overfitting

    EX) k=1이라고 하면 분류 정확도가 상당히 낮을 수밖에 없다. 시야가 좁아져서 아주 근처에 있는 점 하나에 민감하게 영향을 받기 때문이다.
 
이를 `overfitting(과적합)`이라고 한다

모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어진다는 의미로,

훈련 데이터에 너무 맞추어져 있기 때문에 훈련 데이터 이외의 다양한 변수에는 대응하기 힘들다.

KNN 알고리즘에서는 주변 다른 이웃들까지 충분히 고려하지 않았을 때 오버피팅이 발생한다.
 
그래서 하나의 이상치(outlier)가 있을 경우 근처에 있는 점의 레이블이 그 이상치에 의해 결정될 수 있다.

<br>

### k가 너무 클 때 : Underfitting

    EX) 학습 세트에 100개의 점이 있고 k=100으로 설정했다고 극단적으로 가정하면, 모든 점이 결국 동일한 방식으로 분류될 것이다. 즉, 점 사이의 거리는 의미가 없어진다.

k가 너무 큰 경우에는 `underfitting(과소적합)`이 발생한다.

모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생
 
underfitting은 분류기가 학습 세트의 세세한 부분에 충분히 주의를 기울이지 않았기 때문에 나타난다. 
 
즉, k가 너무 그면 분류기가 학습 데이터를 충분히 세세하게 살펴보지 못한다는 뜻이다.

> 결론 : k가 작으면 과적합이 발생하여 정확도가 상대적으로 낮다. 반면 k가 너무 커져도 과소 적합이 발생해서 정확도가 떨어진다. 즉, 너무 작지도 크지도 않은 k를 고르는 것이 중요하다.

<br>

참고자료

https://kkokkilkon.tistory.com/14

http://hleecaster.com/ml-knn-concept/

http://hleecaster.com/ml-knn-classifier-example/

https://m.blog.naver.com/PostView.nhn?blogId=qbxlvnf11&logNo=221324122821&proxyReferer=https%3A%2F%2Fwww.google.com%2F


<br>

# Matrix Factorization

[참고자료 : 협업 필터링](#참고-:-Colloabrative-Filtering)

[참고자료 : Explicit, Implicit Dataset](#참고-:-Explicit-Dataset)

## 개념

MF는 사용자의 기호 데이터를 행렬로 만든다.

모든 사용자가 모든 컨텐츠를 소비할 수는 없기 때문에 이 행렬은 비어있는(sparse)행렬이 된다.

MF는 이렇게 표현한 행렬의 비어있는 부분을 채우는 기술을 통틀어 이르는 말이다.

## 특징

유저간, 혹은 아이템간 유사도를 이용하는 Memory-based 방법과 달리, MF는 행렬 인수 분해라는 수학적 방법으로 접근한다.

이는 행렬은 두개의 하위 행렬로 분해가 가능하며, 다시 곱해져서 원래 행렬과 동일한 크기의 단일 행렬이 될 수 있다는 성질에 기인한 것이다.

## 방법

1. 크기 U X M을 가지는 rating matrix R이 있다고 가정한다.

2. 이때 R은 각각의 크기가 U X K, M X K인 두 개의 행렬 P와 Q로 분해될 수 있다고 가정한다.

3. 그리고 다시 P X Q 행렬을 계산하면, 원래의 matrix R와 굉장히 유사하며 크기가 동일한 행렬이 생성된다. 중요한 것은, 행렬이 재생성 되면서 빈공간이 채워진다는 것이다. 이러한 행렬 인수 분해의 원칙은 비평가 항목을 채우기 위함이라는 것을 알 수 있다. 

<hr>

## 참고 : Colloabrative Filtering (협업 필터링)

> 내가 남긴 평점 데이터를 가지고 나와 취향이 비슷한 사람이 선호하는 아이템을 추천

> Collaborative Filtering에서는 프로필 데이터 없이, 사용자의 과거 행동 데이터만 가지고 추천을 진행


    EX) 왓챠를 떠올려보면 사용자는 자신이 본 영화들에 대해서 1점부터 5점까지 평점을 남긴다.

    이제 이 평점들을 가지고 사용자의 취향을 파악한 뒤, 선호할 만한 영화를 추천해주는 방식이다.


### 장점

도메인 제약없이 데이터 셋을 쌓기가 쉽다.

또한 일반적으로 Contents Based Filtering 보다 더 정확하다고 알려져 있다.


### 단점

신규 사용자의 경우, 관찰된 행동 데이터가 없거나 적다.

이런 경우 추천의 정확도가 급격히 떨어지는 Cold start 문제가 발생한다.

<hr>

## 참고 : Explicit Dataset

> 사용자가 아이템에 대하여 선호와 비선호를 명확하게 구분해준 데이터 셋

    EX) 영화 평점 처럼 해당 영화가 좋을 시에는 5점, 별로인 경우에는 1점을 매겨주는 것

## 참고: Implicit Dataset

> Implicit Dataset은 호불호 구분 없이 사용자가 아이템을 얼마나 소비하였는지를 기록한 데이터 셋

    EX) 쇼핑몰의 클릭 로그

    사용자는 관심이 가는 상품을 쇼핑몰 상에서 클릭하게 된다.

    여러번 클릭한 상품은 확실히 선호하는 상품으로 간주할 수 있다.

    하지만 관심이 없는 상품은 관심이 없다고 표시하여 주지 않는다.

    또한 클릭을 하지 않았다고 하여 그 아이템을 선호하지 않는다고 볼 수 없다.

    단지 보지 못해서 클릭을 안 했을 수도 있고, 선호하지 않아서 클릭을 안 했을 수도 있다.



Implicit Dataset은 사용자가 어떤 아이템을 선호하는 지는 알지만, 어떤 아이템을 비 선호하는지 알지 못한다.

클릭 로그가 비어있는(예를들면 클릭하지 않은) 상품 안에는 사용자가 좋아하는 아이템이 있을 수도, 없을 수도 있다.

때문에 ? 에 해당하는 영역 역시 데이터로 포함하여 사용자의 선호도를 학습한다.

<br>

## Implicit - Explicit 비교

rating은 Netflix처럼 1에서 5 사이의 real value일수도 있으며, 아마존이나 페이스북처럼 클릭했는지 하지 않았는지에 대한 데이터일수도 있다.

앞선 경우(1과 5사이의 값)는 사용자가 자신이 얼마나 이 아이템을 좋아하는지 ‘명시적으로’ 나타냈기 때문에 explicit feedback이라 부르며,

후자의 경우(클락했는지의 여부)는 사용자가 해당 상품을 좋아했는지 싫어했는지 표현을 직접적으로 하지 않으므로 ‘implicit feedback’이라고 부른다.

참고자료

https://yeomko.tistory.com/3

https://yeomko.tistory.com/6?category=805638